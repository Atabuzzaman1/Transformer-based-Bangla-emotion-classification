{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttblj2dvC3pA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Embedding,SpatialDropout1D\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('bangla_emotions_dataset_11927.csv',encoding='utf-8')\n",
        "#df=df.drop('Unnamed: 0',axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "H0iPaMliDIn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.labels.value_counts()"
      ],
      "metadata": {
        "id": "5mMqWiI8DLYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot encode the lab\n",
        "'''\n",
        "df.loc[df['label'] == 'happy', 'Label'] = 0\n",
        "df.loc[df['label'] == 'angry', 'Label'] = 1\n",
        "df.loc[df['label'] == 'sad', 'Label'] = 2\n",
        "df.loc[df['label'] == 'disgust', 'Label'] = 3\n",
        "df.loc[df['label'] == 'surprise', 'Label'] = 4\n",
        "df.loc[df['label'] == 'fear', 'Label'] = 5\n",
        "print(df['Label'][:10])\n",
        "'''\n",
        "y = to_categorical(df['labels'], num_classes=6)\n",
        "print(y[:10])\n",
        "if 'label' in df.keys():\n",
        "    df.drop(['label'], axis=1)"
      ],
      "metadata": {
        "id": "F_37VshTDOx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "RSHIwQLhDTuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df['ctexts']\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "7H6Mfc9MDa8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "hfVk4Y_EDdtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = 20000\n",
        "tokenizer = Tokenizer(num_words=num_words)\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"vocab size:\", vocab_size)"
      ],
      "metadata": {
        "id": "OjlMB7e1DhBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 128\n",
        "X = pad_sequences(X, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "BpZebcFdDm9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "id": "7aHwNzv2DrN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, label_train, label_test = train_test_split(X, y, test_size=0.25,shuffle=True)"
      ],
      "metadata": {
        "id": "vxHigxOSDuMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training:\", len(X_train), len(label_train))\n",
        "print(\"Testing: \", len(X_test), len(label_test))"
      ],
      "metadata": {
        "id": "myGBbXqPDxG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training:\", X_train.shape, label_train.shape)\n",
        "print(\"Testing: \", X_test.shape,label_test.shape)"
      ],
      "metadata": {
        "id": "E_fCNJDDD0kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "#from keras.layers import GaussianNoise, BatchNormalization\n",
        "from keras.layers import Dense,Conv1D,MaxPooling1D, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "XWwpADOpD3H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PJWiYsTD6KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "1oXv2kpaEHm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "dropout = 0.2\n",
        "opt = 'adam'\n",
        "#clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=num_words,\n",
        "                           output_dim=embedding_dim,\n",
        "                           input_length=maxlen))\n",
        "\n",
        "model.add(layers.LSTM(100, dropout=dropout,recurrent_dropout=dropout,return_sequences=True))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(BatchNormalization()) #normalization\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer='l2')) #regularizer\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yST9wYwjEJFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, label_train,\n",
        "                    epochs=30,\n",
        "                    verbose=True,\n",
        "                    validation_split=0.1,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[EarlyStopping(monitor='val_acc',patience=7, min_delta=0.0001,verbose=1)])\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, label_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "loss_val, accuracy_val = model.evaluate(X_test, label_test, verbose=True)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy_val))"
      ],
      "metadata": {
        "id": "ZvKcPFc_EfIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zxMrWugkEVlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix,classification_report\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test),axis=1)\n",
        "y_test=np.argmax(label_test,axis=1)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Gmg6f7iUEaDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7p4GrlCOEkg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BiLSTM"
      ],
      "metadata": {
        "id": "5v-GgIxGElsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "dropout = 0.2\n",
        "opt = 'adam'\n",
        "#clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=num_words,\n",
        "                           output_dim=embedding_dim,\n",
        "                           input_length=maxlen))\n",
        "\n",
        "model.add(layers.Bidirectional(layers.LSTM(100, dropout=dropout,\n",
        "                                           recurrent_dropout=dropout,\n",
        "                                           return_sequences=True)))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(BatchNormalization()) #normalization\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer='l2')) #regularizer\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "B8nwFC2uEnqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, label_train,\n",
        "                    epochs=30,\n",
        "                    verbose=True,\n",
        "                    validation_split=0.1,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[EarlyStopping(monitor='val_acc',patience=7, min_delta=0.0001,verbose=1)])\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, label_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "loss_val, accuracy_val = model.evaluate(X_test, label_test, verbose=True)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy_val))"
      ],
      "metadata": {
        "id": "JkeZub_VFCWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LN7d2qtyFCZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix,classification_report\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test),axis=1)\n",
        "y_test=np.argmax(label_test,axis=1)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "5F8Xm4PhFH1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b68y0G6VFLKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN-BiLSTM"
      ],
      "metadata": {
        "id": "BrCg4drnFLXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "embedding_dim = 100\n",
        "dropout = 0.2\n",
        "opt = 'adam'\n",
        "#clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=maxlen))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(layers.Bidirectional(layers.LSTM(100, dropout=dropout,\n",
        "                                           recurrent_dropout=dropout,\n",
        "                                           return_sequences=True)))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(BatchNormalization()) #normalization\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(128, kernel_regularizer='l2')) #regularizer\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(dropout))\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l2LqHhY6FNgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, label_train,\n",
        "                    epochs=30,\n",
        "                    verbose=True,\n",
        "                    validation_split=0.1,\n",
        "                    batch_size=128,\n",
        "                    callbacks=[EarlyStopping(monitor='val_acc',patience=7, min_delta=0.0001)])\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, label_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "loss_val, accuracy_val = model.evaluate(X_test, label_test, verbose=True)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy_val))"
      ],
      "metadata": {
        "id": "Q7DVVXOkFTRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J3BgajptFeei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix,classification_report\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test),axis=1)\n",
        "y_test=np.argmax(label_test,axis=1)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Sc5guXlVFTTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8mPjPduFTXC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}